#!/usr/bin/env python3
"""
GPUæ£€æµ‹å’Œé…ç½®è„šæœ¬
æ£€æŸ¥GPUå¯ç”¨æ€§å¹¶é…ç½®è®­ç»ƒç¯å¢ƒ
"""

import torch
import os
import logging
import subprocess
import sys

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def check_gpu_availability():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    logging.info("=== GPUå¯ç”¨æ€§æ£€æŸ¥ ===")
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    cuda_available = torch.cuda.is_available()
    logging.info(f"CUDAå¯ç”¨: {cuda_available}")
    
    if cuda_available:
        # è·å–GPUæ•°é‡
        gpu_count = torch.cuda.device_count()
        logging.info(f"GPUæ•°é‡: {gpu_count}")
        
        # è·å–å½“å‰GPU
        current_device = torch.cuda.current_device()
        logging.info(f"å½“å‰GPUè®¾å¤‡: {current_device}")
        
        # è·å–GPUä¿¡æ¯
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3  # GB
            logging.info(f"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
        
        # æ£€æŸ¥å½“å‰GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        if gpu_count > 0:
            memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
            memory_reserved = torch.cuda.memory_reserved() / 1024**3  # GB
            logging.info(f"å½“å‰GPUå†…å­˜ä½¿ç”¨: {memory_allocated:.2f} GB (å·²åˆ†é…) / {memory_reserved:.2f} GB (å·²ä¿ç•™)")
        
        return True, gpu_count
    else:
        logging.warning("CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
        return False, 0

def check_nvidia_smi():
    """ä½¿ç”¨nvidia-smiæ£€æŸ¥GPUçŠ¶æ€"""
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            logging.info("nvidia-smiè¾“å‡º:")
            print(result.stdout)
        else:
            logging.error("nvidia-smiå‘½ä»¤å¤±è´¥")
    except FileNotFoundError:
        logging.warning("nvidia-smiå‘½ä»¤ä¸å¯ç”¨")

def configure_gpu_environment():
    """é…ç½®GPUç¯å¢ƒ"""
    logging.info("=== GPUç¯å¢ƒé…ç½® ===")
    
    # è®¾ç½®CUDAç¯å¢ƒå˜é‡
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    cuda_available, gpu_count = check_gpu_availability()
    
    if cuda_available and gpu_count > 0:
        # è®¾ç½®é»˜è®¤GPU
        os.environ['CUDA_VISIBLE_DEVICES'] = '0'
        logging.info("è®¾ç½®CUDA_VISIBLE_DEVICES=0")
        
        # è®¾ç½®CUDAæ€§èƒ½ä¼˜åŒ–
        os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
        logging.info("è®¾ç½®CUBLAS_WORKSPACE_CONFIG=:4096:8")
        
        # å¯ç”¨TF32ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(torch.backends.cuda, 'matmul'):
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            logging.info("å¯ç”¨TF32ä¼˜åŒ–")
        
        return True
    else:
        logging.warning("æœªæ£€æµ‹åˆ°å¯ç”¨GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
        return False

def test_gpu_training():
    """æµ‹è¯•GPUè®­ç»ƒ"""
    logging.info("=== GPUè®­ç»ƒæµ‹è¯• ===")
    
    try:
        # åˆ›å»ºæµ‹è¯•å¼ é‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logging.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åˆ›å»ºæµ‹è¯•æ¨¡å‹
        test_model = torch.nn.Linear(100, 10).to(device)
        test_input = torch.randn(32, 100).to(device)
        test_target = torch.randint(0, 10, (32,)).to(device)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        with torch.no_grad():
            output = test_model(test_input)
            loss = torch.nn.functional.cross_entropy(output, test_target)
        
        logging.info(f"æµ‹è¯•æŸå¤±: {loss.item():.4f}")
        logging.info("GPUè®­ç»ƒæµ‹è¯•æˆåŠŸ!")
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated() / 1024**2  # MB
            logging.info(f"GPUå†…å­˜ä½¿ç”¨: {memory_used:.2f} MB")
        
        return True
        
    except Exception as e:
        logging.error(f"GPUè®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        return False

def check_pytorch_cuda():
    """æ£€æŸ¥PyTorch CUDAæ”¯æŒ"""
    logging.info("=== PyTorch CUDAæ”¯æŒæ£€æŸ¥ ===")
    
    logging.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    logging.info(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    logging.info(f"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
    
    # æ£€æŸ¥CUDAåŠŸèƒ½
    if torch.cuda.is_available():
        logging.info("CUDAåŠŸèƒ½æ£€æŸ¥:")
        logging.info(f"  - å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
        logging.info(f"  - è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        logging.info(f"  - è®¾å¤‡åç§°: {torch.cuda.get_device_name()}")
        logging.info(f"  - è®¡ç®—èƒ½åŠ›: {torch.cuda.get_device_capability()}")
        
        # æµ‹è¯•åŸºæœ¬CUDAæ“ä½œ
        try:
            x = torch.randn(100, 100).cuda()
            y = torch.randn(100, 100).cuda()
            z = torch.mm(x, y)
            logging.info("  - çŸ©é˜µä¹˜æ³•æµ‹è¯•: é€šè¿‡")
        except Exception as e:
            logging.error(f"  - çŸ©é˜µä¹˜æ³•æµ‹è¯•: å¤±è´¥ - {e}")
    else:
        logging.warning("CUDAä¸å¯ç”¨")

def main():
    """ä¸»å‡½æ•°"""
    logging.info("ğŸš€ å¼€å§‹GPUæ£€æŸ¥å’Œé…ç½®...")
    
    # 1. æ£€æŸ¥PyTorch CUDAæ”¯æŒ
    check_pytorch_cuda()
    
    # 2. æ£€æŸ¥nvidia-smi
    check_nvidia_smi()
    
    # 3. é…ç½®GPUç¯å¢ƒ
    gpu_available = configure_gpu_environment()
    
    # 4. æµ‹è¯•GPUè®­ç»ƒ
    training_success = test_gpu_training()
    
    # æ€»ç»“
    logging.info("=== æ£€æŸ¥ç»“æœæ€»ç»“ ===")
    if gpu_available and training_success:
        logging.info("âœ… GPUé…ç½®æˆåŠŸï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ!")
        logging.info("ğŸ’¡ å»ºè®®çš„è®­ç»ƒé…ç½®:")
        logging.info("   - ä½¿ç”¨GPUè®­ç»ƒ")
        logging.info("   - å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
        logging.info("   - ä½¿ç”¨é€‚å½“çš„æ‰¹æ¬¡å¤§å°")
    else:
        logging.warning("âš  GPUé…ç½®æœ‰é—®é¢˜ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
        logging.info("ğŸ’¡ CPUè®­ç»ƒå»ºè®®:")
        logging.info("   - å‡å°æ‰¹æ¬¡å¤§å°")
        logging.info("   - å‡å°‘æ¨¡å‹å¤æ‚åº¦")
        logging.info("   - è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ•°æ®é›†")
    
    return gpu_available and training_success

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1) 