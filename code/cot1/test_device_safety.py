#!/usr/bin/env python3
"""
è®¾å¤‡å®‰å…¨æ€§æµ‹è¯•è„šæœ¬
æµ‹è¯•è®¾å¤‡ç®¡ç†å™¨çš„å„ç§åŠŸèƒ½
"""

import torch
import logging
from safe_device_utils import DeviceManager, safe_to_device, ensure_model_on_device
from stable_cot_module import LightweightCoTModule
from configs import cfg

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def test_device_manager():
    """æµ‹è¯•è®¾å¤‡ç®¡ç†å™¨"""
    logging.info("=== æµ‹è¯•è®¾å¤‡ç®¡ç†å™¨ ===")
    
    try:
        # åˆ›å»ºè®¾å¤‡ç®¡ç†å™¨
        device_manager = DeviceManager()
        logging.info(f"è®¾å¤‡ç®¡ç†å™¨åˆ›å»ºæˆåŠŸï¼Œè®¾å¤‡: {device_manager.get_device()}")
        
        # æµ‹è¯•æ¨¡å‹ç§»åŠ¨
        test_model = torch.nn.Linear(100, 10)
        moved_model = device_manager.ensure_model_on_device(test_model)
        logging.info(f"æ¨¡å‹ç§»åŠ¨æˆåŠŸ: {next(moved_model.parameters()).device}")
        
        # æµ‹è¯•å¼ é‡ç§»åŠ¨
        test_tensor = torch.randn(10, 10)
        moved_tensor = device_manager.move_to_device(test_tensor)
        logging.info(f"å¼ é‡ç§»åŠ¨æˆåŠŸ: {moved_tensor.device}")
        
        return True
        
    except Exception as e:
        logging.error(f"è®¾å¤‡ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cot_module_device():
    """æµ‹è¯•CoTæ¨¡å—è®¾å¤‡ç®¡ç†"""
    logging.info("=== æµ‹è¯•CoTæ¨¡å—è®¾å¤‡ç®¡ç† ===")
    
    try:
        # åˆ›å»ºCoTæ¨¡å—
        cot_module = LightweightCoTModule(cfg)
        logging.info("CoTæ¨¡å—åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è®¾å¤‡ç®¡ç†å™¨
        device_manager = DeviceManager()
        cot_module = device_manager.ensure_model_on_device(cot_module)
        logging.info(f"CoTæ¨¡å—è®¾å¤‡: {next(cot_module.parameters()).device}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_image_features = torch.randn(2, 512)
        test_text_features = torch.randn(2, 512)
        
        # ç§»åŠ¨åˆ°æ­£ç¡®è®¾å¤‡
        device = device_manager.get_device()
        test_image_features = test_image_features.to(device)
        test_text_features = test_text_features.to(device)
        
        with torch.no_grad():
            reasoning_features, reasoning_text = cot_module(
                test_image_features, 
                test_text_features,
                "Test image description", 
                "Test text content", 
                "hate"
            )
        
        logging.info(f"CoTæ¨¡å—å‰å‘ä¼ æ’­æˆåŠŸï¼Œæ¨ç†ç‰¹å¾è®¾å¤‡: {reasoning_features.device}")
        
        return True
        
    except Exception as e:
        logging.error(f"CoTæ¨¡å—è®¾å¤‡ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_safe_device_functions():
    """æµ‹è¯•å®‰å…¨è®¾å¤‡å‡½æ•°"""
    logging.info("=== æµ‹è¯•å®‰å…¨è®¾å¤‡å‡½æ•° ===")
    
    try:
        # æµ‹è¯•safe_to_device
        test_tensor = torch.randn(5, 5)
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        moved_tensor = safe_to_device(test_tensor, device)
        logging.info(f"safe_to_deviceæµ‹è¯•æˆåŠŸ: {moved_tensor.device}")
        
        # æµ‹è¯•ensure_model_on_device
        test_model = torch.nn.Linear(50, 10)
        moved_model = ensure_model_on_device(test_model, device)
        logging.info(f"ensure_model_on_deviceæµ‹è¯•æˆåŠŸ: {next(moved_model.parameters()).device}")
        
        # æµ‹è¯•éå¼ é‡å¯¹è±¡
        non_tensor = "test_string"
        result = safe_to_device(non_tensor, device)
        logging.info(f"éå¼ é‡å¯¹è±¡æµ‹è¯•æˆåŠŸ: {type(result)}")
        
        return True
        
    except Exception as e:
        logging.error(f"å®‰å…¨è®¾å¤‡å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_device_consistency():
    """æµ‹è¯•è®¾å¤‡ä¸€è‡´æ€§"""
    logging.info("=== æµ‹è¯•è®¾å¤‡ä¸€è‡´æ€§ ===")
    
    try:
        device_manager = DeviceManager()
        
        # åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡
        batch = {
            'image_features': torch.randn(2, 512),
            'text_features': torch.randn(2, 512),
            'labels': torch.randint(0, 2, (2,)),
            'image_descriptions': ['desc1', 'desc2'],
            'text_contents': ['text1', 'text2']
        }
        
        # åˆ›å»ºæµ‹è¯•æ¨¡å‹
        model = torch.nn.Linear(512, 10)
        
        # æ£€æŸ¥è®¾å¤‡ä¸€è‡´æ€§
        is_consistent = device_manager.check_batch_device(batch, model)
        logging.info(f"è®¾å¤‡ä¸€è‡´æ€§æ£€æŸ¥: {is_consistent}")
        
        # ä¿®å¤è®¾å¤‡ä¸€è‡´æ€§
        fixed_batch = device_manager.fix_batch_device(batch, model)
        logging.info("è®¾å¤‡ä¸€è‡´æ€§ä¿®å¤å®Œæˆ")
        
        # å†æ¬¡æ£€æŸ¥
        is_consistent_after = device_manager.check_batch_device(fixed_batch, model)
        logging.info(f"ä¿®å¤åè®¾å¤‡ä¸€è‡´æ€§: {is_consistent_after}")
        
        return True
        
    except Exception as e:
        logging.error(f"è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_pytorch_lightning_compatibility():
    """æµ‹è¯•PyTorch Lightningå…¼å®¹æ€§"""
    logging.info("=== æµ‹è¯•PyTorch Lightningå…¼å®¹æ€§ ===")
    
    try:
        import pytorch_lightning as pl
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„Lightningæ¨¡å—
        class TestModule(pl.LightningModule):
            def __init__(self):
                super().__init__()
                self.linear = torch.nn.Linear(10, 1)
                # ä¸è¦ç›´æ¥è®¾ç½®deviceå±æ€§
                # self.device = torch.device('cuda')  # è¿™ä¼šå¯¼è‡´é”™è¯¯
            
            def forward(self, x):
                return self.linear(x)
            
            def training_step(self, batch, batch_idx):
                x, y = batch
                y_hat = self(x)
                loss = torch.nn.functional.mse_loss(y_hat, y)
                return loss
            
            def configure_optimizers(self):
                return torch.optim.Adam(self.parameters())
        
        # åˆ›å»ºæ¨¡å‹
        model = TestModule()
        logging.info("PyTorch Lightningæ¨¡å—åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è®¾å¤‡ç®¡ç†å™¨
        device_manager = DeviceManager()
        model = device_manager.ensure_model_on_device(model)
        logging.info(f"æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
        
        return True
        
    except Exception as e:
        logging.error(f"PyTorch Lightningå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logging.info("ğŸš€ å¼€å§‹è®¾å¤‡å®‰å…¨æ€§æµ‹è¯•...")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        test_device_manager,
        test_cot_module_device,
        test_safe_device_functions,
        test_device_consistency,
        test_pytorch_lightning_compatibility
    ]
    
    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            logging.error(f"æµ‹è¯• {test.__name__} å¤±è´¥: {e}")
            results.append(False)
    
    # æ€»ç»“ç»“æœ
    passed = sum(results)
    total = len(results)
    logging.info(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        logging.info("ğŸ‰ æ‰€æœ‰è®¾å¤‡å®‰å…¨æ€§æµ‹è¯•é€šè¿‡!")
        logging.info("ğŸ’¡ ç°åœ¨å¯ä»¥å®‰å…¨åœ°ä½¿ç”¨è®¾å¤‡ç®¡ç†å™¨è¿›è¡Œè®­ç»ƒ")
    else:
        logging.error("âŒ éƒ¨åˆ†è®¾å¤‡å®‰å…¨æ€§æµ‹è¯•å¤±è´¥!")
        logging.info("ğŸ’¡ è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜")
    
    return passed == total

if __name__ == '__main__':
    success = main()
    import sys
    sys.exit(0 if success else 1) 